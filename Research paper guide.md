# **Paper 1: ["Attention Is All You Need"](https://arxiv.org/pdf/1706.03762)  : â€œOne of the most important papers in AI today**

### **From Basics to Mastery: Building and Optimizing Transformers**

* ### Foundation & Prerequisites: Learn PyTorch, Transformers, and NLP fundamentals, including attention mechanisms.

* ### Understanding Transformers: Deep dive into self-attention, positional encoding, and multi-head attention to grasp Transformer architecture.

* ### Building & Fine-Tuning: Use Hugging Faceâ€™s transformers library to fine-tune pre-trained models on tasks like text classification and sentiment analysis.

* ### Training on Custom Datasets: Apply Transformers to domain-specific datasets for real-world applications like summarization and translation.

* ### Optimization & Debugging: Enhance training efficiency with gradient clipping, learning rate scheduling, model checkpointing, and mixed precision training.

* ### Final Project: Integrate all learnings to train, fine-tune, and optimize a Transformer model for a practical NLP application. 

# **Paper 2:[GANs for Image Generation (DCGAN Implementation in PyTorch)](https://arxiv.org/pdf/1511.06434)**

### **From Basics to Mastery: Implementing DCGAN for Image Generation**

* ### Foundation & Prerequisites: Learn PyTorch basics, deep learning concepts, and generative models, focusing on Convolutional Neural Networks (CNNs) and GAN fundamentals.

* ### Understanding GANs & DCGAN: Study Generative Adversarial Networks (GANs) and how Deep Convolutional GANs (DCGANs) improve stability and performance.

* ### Building the DCGAN Architecture: Implement the generator and discriminator networks using PyTorch, following the architectural guidelines from the paper.

* ### Training on Image Datasets: Use datasets like CIFAR-10, CelebA, or MNIST to train the DCGAN, adjusting hyperparameters for better image generation.

* ### Optimization & Debugging: Improve training with loss function tuning, learning rate adjustments, batch normalization, and avoiding mode collapse.

* ### Final Project: Train a custom DCGAN on a dataset of your choice, generate high-quality images, and analyze the model's performance. 

### 

### 

### 

## **Paper 1: "Attention Is All You Need"**

The **"Attention Is All You Need"** paper introduced the **Transformer** architecture, which has since revolutionized the field of **Natural Language Processing (NLP)**. The model relies entirely on **self-attention mechanisms** instead of recurrence (RNNs) or convolution (CNNs), enabling **parallelization** and significantly improving the performance of NLP tasks like translation and text generation.

---

## **1\. High-Level Overview of Implementation**

### **Goal of the Paper**

The paper proposes a **Transformer model**, an **encoder-decoder** architecture that relies on **self-attention and positional encoding** instead of sequential processing, allowing for more efficient and scalable NLP models. The primary goal is to improve **machine translation** performance (e.g., English to German translation) while reducing training time.

### **Target Audience**

* **Intermediate to Advanced Practitioners** with a solid understanding of deep learning, NLP, and PyTorch  
* Some knowledge of **sequence-to-sequence (seq2seq) models**, **attention mechanisms**, and **Transformer architectures** is recommended.

### **Preferred Frameworks & Programming Languages**

* **PyTorch** for model implementation.  
* **Hugging Face Transformers** for efficient pre-trained implementations.  
* **Jupyter Notebooks or Google Colab** for experimentation.

### **Hardware/Software Resources**

* **GPU Required**: The Transformer model is computationally expensive. Using Google Colab (with a free GPU) or an NVIDIA GPU  is recommended.  
* **Deep Learning Libraries**: PyTorch, TensorFlow, Hugging Face Transformers, and tokenization libraries.

---

## 

## **2\. Key Prerequisites**

### **a. Libraries and Tools**

Before implementing, install the necessary libraries:

`# Install required libraries`  
`!pip install torch torchvision transformers datasets tokenizers sacrebleu sentencepiece`

* **PyTorch / TensorFlow** â€“ Deep learning frameworks.  
* **Hugging Face Transformers** â€“ Pre-trained Transformer models.  
* **Datasets (Hugging Face, OpenSubtitles, WMT14, or IWSLT)** â€“ For training/testing.  
* **Matplotlib & Seaborn** â€“ For visualization.

### **b. Fundamental Concepts to Understand**

1. **Self-Attention Mechanism** â€“ Allows the model to weigh input tokens based on relevance.  
2. **Positional Encoding** â€“ Since Transformers lack recurrence, positional information is injected into embeddings.  
3. **Multi-Head Attention** â€“ Uses multiple attention heads to learn different representations.  
4. **Feed-Forward Network (FFN)** â€“ Fully connected layers after attention layers.  
5. **Layer Normalization & Residual Connections** â€“ Stabilizes training.  
6. **Masked Self-Attention** â€“ Used in the decoder to prevent peeking at future words.

**Roadmap for Implementing: "Attention Is All You Need"**  
---

## **ğŸ—“ï¸ Week 0: Understanding Prerequisites**

Before implementing the Transformer, you should be comfortable with:

1. **Linear Algebra & Matrices** (Matrix multiplication, dot product)  
2. **Probability & Statistics** (Softmax, distributions)  
3. **Deep Learning Basics** (Backpropagation, optimization, activation functions)  
4. **Sequence Modeling** (RNNs, LSTMs, why they struggle with long sequences)  
5. **Self-Attention Mechanism**

### **ğŸ¥ Recommended Videos**

* **Attention Mechanism Explained** â†’ https://youtu.be/eMlx5fFNoYc?si=Cl6eVTP\_EhygRwmW  
* **Transformers for Beginners (Simplified Explanation)** â†’ [https://youtu.be/kCc8FmEb1nY](https://youtu.be/kCc8FmEb1nY)   
* **RNN explained** â†’  [https://www.youtube.com/watch?v=AsNTP8Kwu80\&t=292s](https://www.youtube.com/watch?v=AsNTP8Kwu80&t=292s) [https://www.youtube.com/watch?v=Gafjk7\_w1i8](https://www.youtube.com/watch?v=Gafjk7_w1i8)  
* **Recommended PyTorch Tutorials** â†’ [https://www.youtube.com/watch?v=FHdlXe1bSe4](https://www.youtube.com/watch?v=FHdlXe1bSe4)  
* **What are NLPs?** â†’ [https://www.youtube.com/watch?v=CMrHM8a3hqw](https://www.youtube.com/watch?v=CMrHM8a3hqw)  
* **Getting started with hugging Face**  â†’  [https://youtu.be/QEaBAZQCtwE?si=lxJhzvguRb-EZtvT](https://youtu.be/QEaBAZQCtwE?si=lxJhzvguRb-EZtvT)  
* **Why Self-Attention Beats RNNs** â†’ https://www.youtube.com/watch?v=EFkbT-1VGTQ  
* **Math Behind Softmax & Dot Product Attention** â†’ [https://youtu.be/KphmOJnLAdI?si=4SLWJslEk7LYRnC7](https://youtu.be/KphmOJnLAdI?si=4SLWJslEk7LYRnC7)  
* ğŸ“ **Goal for Week 0:**  
  By the end of this week, you should understand the core concepts behind the Transformer, why it replaces RNNs, and how attention works.

---

## **ğŸ—“ï¸ Week 1: Understanding the Transformer Architecture**

### **ğŸ“Œ Steps:**

1. Read **Sections 1 & 2** of the paper: Introduction \+ Background.  
2. Identify the **main components** of the Transformer:  
   * Multi-Head Self-Attention  
   * Positional Encoding  
   * Feed-Forward Networks  
   * Residual Connections & Layer Normalization  
3. **Sketch the full architecture** on paper (helps in visualization).  
4. **This video will help you to understand the paper:** 

ğŸ¥ **Video for Understanding the Architecture:**

* **Illustrated Transformer (Deep Dive)** â†’ [https://youtu.be/4Bdc55j80l8](https://youtu.be/4Bdc55j80l8) 

ğŸ“ **Goal for Week 1:**  
Understand the high-level structure of the Transformer and its components.

---

## **ğŸ—“ï¸ Week 2: Implementing Key Components**

### **Step 1: Paper Breakdown & Key Equations (Day 3-4)**

ğŸ¥ Watch:

* [Attention Is All You Need â€“ Yannic Kilcher](https://www.youtube.com/watch?v=iDulhoQ2pro) (\~32 min)

ğŸ’» **Task:**

* Read the **"Attention Is All You Need"** paper and focus on sections **3 & 5** (Model Architecture & Training Details).  
* Break down **Scaled Dot-Product Attention** and **Multi-Head Attention** mathematically in your notes.

---

### **Step 2: Implement Scaled Dot-Product Attention**

* Formula: Attention(Q,K,V)= softmax(Q  KTdk)V

ğŸ’»**Task:**

* Implement **Scaled Dot-Product Attention** in PyTorch from scratch.

---

### **Step 3: Implement Multi-Head Attention**

* Instead of a single attention mechanism, **split the input into multiple heads**.

ğŸ¥ Watch:

* [Aladdin Perssonâ€™s Transformer Implementation â€“ Self-Attention](https://www.youtube.com/watch?v=U0s0f995w14) (\~40 min)

ğŸ’» **Task:**

* Validate your implementation by comparing with PyTorchâ€™s built-in `torch.nn.MultiheadAttention`.  
* Debug using small input tensors.

ğŸ“ **Goal for Week 2:**  
Successfully implement Scaled Dot-Product Attention and Multi-Head Attention.

---

## **ğŸ—“ï¸ Week 3: Building the Transformer Model**

### **Step 1: Implement Positional Encoding**

* Implement **positional encoding**, **multi-head attention.**  
* I can provide you with a starter code.

### **Step 2: Stack Encoder and Decoder Layers**

* Implement **Feed-Forward Networks, Layer Normalization, and Residual Connections**.  
* Stack **multiple layers** (6 encoder \+ 6 decoder blocks).

ğŸ¥ **Video for Full Implementation Walkthrough:**

* **Code Walkthrough of Transformer in PyTorch** â†’ [https://youtu.be/U0s0f995w14](https://youtu.be/U0s0f995w14)

ğŸ’» **Task:**

* Implement **positional encoding**, **multi-head attention**, **feed-forward layers**, and **layer normalization** from scratch.  
* Stack multiple encoder layers to form the **full Transformer encoder**.  
* Train on a small toy dataset (e.g., random text sequences).

ğŸ“ **Goal for Week 3:**  
Fully implement and train the Transformer on a simple dataset (e.g., translation task with small-scale data).

---

## **ğŸ—“ï¸ Week 4: Training & Experimenting**

### **ğŸ“Œ Step 1: Fine-Tuning a Transformer with Hugging Face (Day 10-12)**

ğŸ¥ Watch:

* [https://youtu.be/eC6Hd1hFvos?si=zbVtBZmn\_CbkWDdF](https://youtu.be/eC6Hd1hFvos?si=zbVtBZmn_CbkWDdF)  

* ###  **Fine-Tuning BERT for Text Classification (Beginner-Friendly)**

* [https://youtu.be/4QHg8Ix8WWQ?si=bFf9JmyytlH3Po-Z](https://youtu.be/4QHg8Ix8WWQ?si=bFf9JmyytlH3Po-Z)   
  ğŸ“Œ Covers:  
  âœ… Loading a pre-trained BERT model  
  âœ… Fine-tuning on a classification dataset  
  âœ… Using the ğŸ¤— Hugging Face `Trainer` API  
  âœ… Evaluating performance

ğŸ’» **Task:**

* Load a pre-trained Transformer (e.g., `BERT`, `GPT-2`) using Hugging Faceâ€™s `transformers` library.  
* Fine-tune it on a simple NLP task (e.g., text classification, sentiment analysis).  
* Evaluate the performance using validation metrics.

---

### **ğŸ“Œ Step 2: Apply Transformers to a Custom Dataset (Day 13-14)**

ğŸ’» **Task:**

* Train your Transformer model on a domain-specific dataset (e.g., summarization, machine translation).  
* Test its generalization ability.

ğŸ¯ **Final Project Idea:** Implement **Transformer-based text summarization** using a dataset like **CNN/DailyMail**.

---

## **ğŸ—“ï¸ Week 4: Advanced Topics & Optimization**

### **ğŸ“Œ Step 1: Exploring Advanced Transformer Variants** 

ğŸ¥ Watch:

* [Transformers in Vision (ViTs) â€“ Explained](https://www.youtube.com/watch?v=ovB0ddFtzzA) (\~20 min)  
* [https://youtu.be/ewjlmLQI9kc?si=SeAyl6FTqOXlfmEN](https://youtu.be/ewjlmLQI9kc?si=SeAyl6FTqOXlfmEN)  

ğŸ’» **Task:**

* Read about **BERT**, **GPT**, **Vision Transformers (ViTs)**, and how they modify the Transformer architecture.

---

### **ğŸ“Œ Step 2: Optimization & Debugging (Day 17-18)**

ğŸ¥ Watch:

* [https://youtu.be/ks3oZ7Va8HU?si=rimrBHV2Uf6\_jLik](https://youtu.be/ks3oZ7Va8HU?si=rimrBHV2Uf6_jLik)   
* [https://youtu.be/KrQp1TxTCUY?si=57Z0TjECJxtKLFnP](https://youtu.be/KrQp1TxTCUY?si=57Z0TjECJxtKLFnP)   
* [https://youtu.be/81NJgoR5RfY?si=0sSiyjz\_SyFvquZo](https://youtu.be/81NJgoR5RfY?si=0sSiyjz_SyFvquZo) 

ğŸ“Œ Covers:

âœ… **Gradient clipping** to prevent exploding gradients

âœ… **Learning rate scheduling** for efficient training

âœ… How **torch.cuda.amp** speeds up training

âœ… **Model checkpointing** to save and resume training

ğŸ’» **Task:**

* Optimize training time using **gradient clipping**, **learning rate scheduling**, and **model checkpointing**.  
* Try using **mixed precision training** (`torch.cuda.amp`).

---

### **ğŸ¯ Final Outcome**

By the end of this structured plan, you will have:  
âœ… **Understood Transformers theoretically.**  
âœ… **Implemented a Transformer from scratch in PyTorch.**  
âœ… **Fine-tuned a pre-trained Transformer using Hugging Face.**  
âœ… **Applied it to real-world NLP tasks.**

## **Paper 2: "Unsupervised Representation Learning with deep Convolutional GANs (DCGAN)"**

The paper focuses on **Unsupervised Learning** using **Generative Adversarial Networks (GANs)**, specifically **Deep Convolutional GANs (DCGANs)**. DCGANs aim to generate high-quality, realistic images from random noise, by learning a useful representation of the underlying data distribution through unsupervised training. Unlike supervised learning, it doesn't require labeled data, making it especially useful in scenarios where acquiring labeled data is expensive or time-consuming.

---

## **1\. High-Level Overview of Implementation**

### **Goal of the Paper**

* The primary aim of the paper is to explore how Generative Adversarial Networks (GANs) can be used for unsupervised representation learning, specifically using deep convolutional networks (DCGANs). The focus is on generating high-quality images by learning representations from unlabelled data, making it suitable for tasks like image generation and unsupervised feature extraction.

### **Target Audience**

* This paper is geared toward **intermediate practitioners**. Familiarity with neural networks, GANs, and convolutional neural networks (CNNs) would be necessary to implement this paper effectively.

### **Preferred Frameworks & Programming Languages**

* **PyTorch** for model implementation.  
* **TorchVision**: For image datasets and transformations.  
* **Matplotlib/Seaborn**: For plotting and visualizing results.  
* **TensorBoard**: For tracking training progress.  
* **Jupyter Notebooks or Google Colab** for experimentation.

### **Hardware/Software Resources**

* **GPU**: Since GANs require a lot of computational power, using a GPU is highly recommended (available on Google Colab or on a local machine with CUDA support).  
* **Google Colab** is a good option if you donâ€™t have access to powerful GPUs.

---

## **2\. Key Prerequisites**

**Conceptual Prerequisites**:

* Basics of GANs and how they work.  
* Knowledge of convolutional neural networks (CNNs).  
* Understanding of unsupervised learning principles.

**Libraries/Tools**:

* **Google Colab**: For free GPU resources.  
* **PyTorch**: For building and training the DCGAN.  
* **Matplotlib** or **Seaborn**: For visualizing generated images and training metrics.

**Datasets**:

* Use **CIFAR-10**, **MNIST**, or **CelebA** (celebrity face dataset) as they are commonly used for evaluating GANs.

**Roadmap for Implementing DCGAN**  
---

## **ğŸ—“ï¸ Week 0: Understanding Prerequisites**

### ğŸ“**Goals:**

* Familiarize yourself with fundamental concepts required to implement DCGAN.  
* Build a basic understanding of PyTorch, convolutional neural networks (CNNs), and unsupervised learning.

### ğŸ’»**Tasks:**

1. **Understand GAN Basics**:  
   * Learn the theory behind Generative Adversarial Networks (GANs): the generator, discriminator, and adversarial training.  
2. **Review Convolutional Neural Networks (CNNs)**:  
   * Understand how CNN layers (e.g., convolution, pooling, activation) work, as they form the backbone of DCGAN.  
3. **Learn PyTorch Basics**:  
   * Gain familiarity with PyTorch tensors, datasets, and training loops.  
   * Practice building and training simple models in PyTorch.  
4. **Overview of Unsupervised Representation Learning**:  
   * Understand the concept of unsupervised learning and how representation learning can be used for tasks like feature extraction and clustering.

### ğŸ¥**Recommended Videos:**

1. **GAN Basics**:  
   * [What are GANs?](https://youtu.be/MZmNxvLDdV0?si=n0pXrti-5-DQefkq)   
   * [A friendly introduction to GANS](https://youtu.be/8L11aMN5KY8?si=phj-ehoLiCiwQEAH)   
2. **CNN Fundamentals**:  
   * [Convolutional Neural Networks â€“ StatQuest](https://youtu.be/CqOfi41LfDw?si=gWGfTmwgZEcy0fB-) (17 min).  
   * [Understanding CNN Layers â€“ Deeplizard](https://www.youtube.com/watch?v=aircAruvnKk) (13 min).  
3. **PyTorch Basics**:  
   * [PyTorch for Beginners â€“ freeCodeCamp](https://www.youtube.com/watch?v=GIsg-ZUy0MY) (3 hours, split into parts).  
   * [PyTorch Tensors Explained â€“ StatQuest](https://youtu.be/L35fFDpwIM4?si=DbsNQRwG2IKTQard)   
4. **Unsupervised Representation Learning**:  
   * [Unsupervised Learning Overview](https://youtu.be/yteYU_QpUxs?si=yiFT2V_ewCUD0EPS) 

---

## **ğŸ—“ï¸Week 1: Understanding DCGAN and Setting Up the Environment**

### ğŸ“**Goals:**

* Gain a solid understanding of GANs and DCGAN.  
* Set up the environment (Google Colab, PyTorch, and required libraries).

### ğŸ’»**Tasks:**

1. **Study GANs and DCGAN Concepts**:  
   * Watch tutorials explaining the theory behind GANs and DCGANs.  
   * Focus on understanding the generator-discriminator architecture and their loss functions.  
2. **Set Up Environment**:  
   * Open Google Colab and configure the runtime with GPU support.  
   * Install required libraries (`torch`, `torchvision`, `matplotlib`, etc.).

### ğŸ¥**Recommended Videos:**

1. **GANs Explained**:  
   * [Generative Adversarial Networks (GANs) Explained â€“ Yannic Kilcher](https://www.youtube.com/watch?v=8L11aMN5KY8) (25 min).  
2. **Introduction to DCGAN**:  
   * [DCGAN Explained](https://youtu.be/xBX2VlDgd4I?si=kXHOV0yjQhT-zfLh)  (15 min).  
3. **Google Colab \+ PyTorch Setup**:  
   * [PyTorch Tutorial for Beginners â€“ Simplilearn](https://www.youtube.com/watch?v=Z_ikDlimN6A) (20 min).

---

## **ğŸ—“ï¸Week 2: Loading Dataset and Preprocessing**

### ğŸ“**Goals:**

* Download a dataset (CIFAR-10, CelebA, or MNIST).  
* Apply transformations and prepare the data for training.

### ğŸ’»**Tasks:**

1. **Choose a Dataset**:  
   * Download CIFAR-10 or CelebA using PyTorch's `torchvision.datasets`.  
   * Alternatively, upload your custom dataset to Google Colab.  
2. **Preprocess the Data**:  
   * Resize images to 64x64.  
   * Normalize pixel values to the range \[-1, 1\] for stable GAN training.  
3. **Test Dataloader**:  
   * Ensure data batches are loading correctly using PyTorch's `DataLoader`.

### ğŸ¥**Recommended Videos:**

1. **Data Loading in PyTorch**:  
   * [PyTorch Datasets and DataLoaders â€“ Simplilearn](https://www.youtube.com/watch?v=ZoZHd0Zm3RY)   
2. **Preprocessing Data for GANs**:  
   * [PyTorch GAN Data Preprocessing and Loading](https://youtu.be/6sDzJZIZdtM?si=jSKSwJuATT64uKMY) 

---

## **ğŸ—“ï¸Week 3: Implementing Generator and Discriminator**

### ğŸ“ **Goals:**

* Write the PyTorch code for the DCGAN generator and discriminator.  
* Initialize weights and prepare optimizers and loss functions.

### ğŸ’»**Tasks:**

1. **Implement the Generator**:  
   * Use `ConvTranspose2d` layers for upsampling noise into 64x64 images.  
2. **Implement the Discriminator**:  
   * Use `Conv2d` layers for downsampling images into a scalar prediction (real/fake).  
3. **Define Loss Function and Optimizer**:  
   * Use Binary Cross-Entropy Loss (BCE).  
   * Use the Adam optimizer with `lr=0.0002` and `betas=(0.5, 0.999)`.

### ğŸ¥**Recommended Videos:**

1. **DCGAN Implementation (Generator & Discriminator)**:  
   * [DCGAN Implementation from Scratch in PyTorch â€“ Aladdin Persson](https://www.youtube.com/watch?v=IZtv9s_Wx9I) (35 min).  
2. **Understanding Optimizers in PyTorch**:  
   * [Adam Optimizer Explained](https://www.youtube.com/watch?v=JXQT_vxqwIs) .

---

## 

## **ğŸ—“ï¸Week 4: Training, Evaluating, and Visualizing Results**

### ğŸ“**Goals:**

* Train the DCGAN on the dataset.  
* Save and visualize generated images.  
* Troubleshoot common issues like mode collapse and unstable training.

### ğŸ’»**Tasks:**

1. **Write Training Loop**:  
   * Alternate training the generator and discriminator.  
   * Log losses and save generated images periodically.  
2. **Evaluate Generated Images**:  
   * Visualize results using Matplotlib or save them to Google Drive.  
   * Experiment with different noise inputs to observe the diversity of generated samples.  
3. **Troubleshoot Common Issues**:  
   * Monitor training metrics for signs of instability (e.g., mode collapse, vanishing gradients).  
   * Adjust hyperparameters like learning rate or architecture if needed.

### ğŸ¥**Recommended Videos:**

1. **Training DCGAN in PyTorch**:  
   * [Building a GAN from scratch](https://youtu.be/_pIMdDWK5sc?si=ymBJ9FSsBUU--1Mv)   
   * [Pytorch DCGAN Tutorial](https://youtu.be/5RYETbFFQ7s?si=l6ptYkd-WwQl5UuF)  
2. **Visualizing GAN Outputs**:  
   * [Visualize GAN Results](https://poloclub.github.io/ganlab/#:~:text=In%20GAN%20Lab%2C%20a%20random,manifold%20%5BOlah%2C%202014%5D.)   
   * [https://github.com/42x00/Visualize-GAN-Training](https://github.com/42x00/Visualize-GAN-Training) 

