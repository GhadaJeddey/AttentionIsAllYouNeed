# AttentionIsAllYouNeed
This is an implementation from scratch of the Transformer architecture following the official research paper : Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, ≈Å., & Polosukhin, I. (2017). Attention is all you need. Proceedings of the 31st Conference on Neural Information Processing Systems (NeurIPS 2017). 
